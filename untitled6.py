# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Q7qDJwnL6UPOGUAeay0v_dnjMjBf_C7
"""

# Import necessary libraries
import pandas as pd
import numpy as np

# Step 1: Load the dataset
df = pd.read_csv("/content/netflix_movies_detailed_up_to_2025.csv")  # Replace with your dataset path
print("Initial Dataset Overview:\n", df.head())

# Step 2: Check for missing values
print("\nMissing Values Before Cleaning:\n", df.isnull().sum())

# Handle missing values
# Drop rows/columns with excessive missing values
df = df.dropna()  # Drop rows with missing values

# Step 3: Remove duplicates
print("\nDuplicate Rows Before Cleaning:", df.duplicated().sum())
df = df.drop_duplicates()
print("Duplicate Rows After Cleaning:", df.duplicated().sum())

# Step 4: Standardize text data
df['director'] = df['director'].str.lower().str.strip()  # Replace 'text_column' with actual column name

# Step 5: Standardize date formats
df['date_added'] = pd.to_datetime(df['date_added'], format='%d-%m-%Y', errors='coerce')  # Replace 'date_column'

# Step 6: Validate and fix data types
df['rating'] = df['rating'].astype(int)  # Replace 'numerical_column'

# Step 7: Rename columns
df.columns = df.columns.str.lower().str.replace(" ", "_")  # Standardize column names
print("\nUpdated Column Names:\n", df.columns)

# Step 8: Save the cleaned dataset
df.to_csv("cleaned_dataset.csv", index=False)
print("\nData Cleaning Complete. Cleaned dataset saved as 'cleaned_dataset.csv'.")

# Step 10: Summary of Changes
summary = {
    "Missing Values": df.isnull().sum().to_dict(),
    "Duplicates Removed": True,
    "Text Standardized": ["director"],  # List columns standardized
    "Date Columns": ["date_added"],  # List standardized date columns
    "Data Types Fixed": ["rating"],  # List fixed columns
}
print("\nSummary of Changes:\n", summary)